# ğŸš€ Quick Start Guide - Streamlit Version

This guide will help you get ClarifyMeet AI running with Streamlit in minutes!

## âš¡ Super Quick Start (Windows)

1. **Double-click `run_streamlit.bat`**
2. Wait for the browser to open
3. Upload a transcript and analyze! ğŸ‰

## ğŸ“‹ Prerequisites

### Required
- **Python 3.11+** ([Download](https://www.python.org/downloads/))
- **Ollama** ([Download](https://ollama.ai/download))

### Installation Steps

#### 1. Install Python
- Download from [python.org](https://www.python.org/downloads/)
- During installation, check "Add Python to PATH"
- Verify: Open PowerShell and run `python --version`

#### 2. Install Ollama
- Download from [ollama.ai/download](https://ollama.ai/download)
- Run the installer
- Ollama will start automatically in the background

#### 3. Download the AI Model
Open PowerShell or Terminal and run:
```bash
ollama pull tinyllama
```

Wait for the download to complete (~637MB).

## ğŸ¯ Running the App

### Option A: Using the Launch Script (Easiest)

**Windows:**
```bash
# Just double-click
run_streamlit.bat

# Or in PowerShell:
.\run_streamlit.bat
```

**Mac/Linux:**
```bash
# Make executable first
chmod +x run_streamlit.sh

# Run it
./run_streamlit.sh
```

### Option B: Manual Start

1. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

2. **Run the app:**
   ```bash
   streamlit run streamlit_app.py
   ```

3. **Open browser:**
   The app will automatically open at http://localhost:8501

## ğŸ“ Using the App

### 1. Prepare a Transcript

Create a `.txt` file with this format:

```text
John: Good morning everyone. Let's start our sprint planning meeting.

Sarah: I'll work on the login page redesign. I can finish it by Friday.

Mike: I'll handle the backend API for authentication. The due date is next Monday.

John: Decision: We will use JWT tokens for authentication.

Sarah: One risk - the design needs approval from stakeholders first.

Mike: I'll also write unit tests for the API endpoints.
```

**Tips:**
- Use `Speaker:` format
- Include dates, decisions, and risks
- Mention task owners clearly

### 2. Upload & Analyze

1. Click **"Choose a transcript file (.txt)"**
2. Select your transcript
3. Click **"ğŸš€ Analyze Transcript"**
4. Wait 30-60 seconds for AI processing

### 3. View Results

Browse through the tabs:
- **ğŸ“‹ Summary**: Key meeting highlights
- **âœ… Action Items**: Tasks with owners and due dates
- **ğŸ’¡ Decisions**: Important decisions made
- **âš ï¸ Risks**: Identified risks and concerns
- **ğŸ‘¥ Speakers**: Participant analysis
- **ğŸ“Š Metadata**: Processing details

### 4. Download Results

Click **"ğŸ“¥ Download JSON Results"** to save the analysis.

## ğŸ¨ What You'll See

### Executive Summary
- Top 3-5 key points from the meeting
- Auto-generated by AI

### Action Items
Each action includes:
- **Description**: What needs to be done
- **Owner**: Who's responsible
- **Due Date**: When it's due
- **Priority**: High/Medium/Low
- **Status**: Pending/In Progress/Done

### Decisions
- What was decided
- Rationale behind it
- Who made the decision
- Context and background

### Risks & Concerns
- Identified risks
- Impact level (High/Medium/Low)
- Mitigation strategies
- Assigned owner

### Speaker Spotlight
- Participant names
- Their roles (PM, Developer, QA, Designer)
- Contribution count
- Key points they raised

## ğŸ”§ Troubleshooting

### "Connection refused" or "Ollama not accessible"

**Fix:**
1. Check if Ollama is running:
   ```bash
   # Windows (PowerShell)
   curl http://localhost:11434/api/tags

   # Mac/Linux
   curl http://localhost:11434/api/tags
   ```

2. If not working, restart Ollama:
   ```bash
   # Windows: Restart from system tray
   # Mac/Linux:
   ollama serve
   ```

### "Model not found: tinyllama"

**Fix:**
```bash
ollama pull tinyllama
ollama list  # Verify it's downloaded
```

### "Module not found: streamlit"

**Fix:**
```bash
pip install -r requirements.txt --upgrade
```

### Port 8501 already in use

**Fix:**
```bash
# Use a different port
streamlit run streamlit_app.py --server.port 8502
```

### Slow processing / Timeout

**Causes:**
- Large transcript (>10MB)
- First run (model loading)
- Limited system resources

**Fix:**
- Use smaller transcripts
- Wait longer on first run
- Close other applications

## ğŸ’¡ Pro Tips

### 1. Better Transcripts = Better Results
- Use clear speaker labels
- Include context (dates, decisions, risks)
- Mention task owners explicitly
- Use relative dates (e.g., "by Friday")

### 2. Optimize Performance
- Keep transcripts under 5000 words
- Use specific speaker names
- Include meeting context

### 3. Understanding AI Confidence
- **High**: Clear ownership, dates, and context
- **Medium**: Some ambiguity detected
- **Low**: Significant uncertainties

### 4. Reviewing Warnings
- Check the **Metadata** tab for warnings
- Address missing owners or dates
- Review low-confidence items

## ğŸŒ Deploying to the Cloud

Want to share with your team? Deploy to Streamlit Cloud:

1. **Push to GitHub:**
   ```bash
   git init
   git add .
   git commit -m "ClarifyMeet AI for Streamlit"
   git remote add origin YOUR_REPO_URL
   git push -u origin main
   ```

2. **Deploy:**
   - Go to [share.streamlit.io](https://share.streamlit.io)
   - Connect your GitHub repo
   - Click "Deploy"

3. **Configure:**
   - Add Ollama host URL in secrets
   - Or switch to OpenAI/Anthropic

See [STREAMLIT_DEPLOYMENT.md](STREAMLIT_DEPLOYMENT.md) for detailed instructions.

## ğŸ“ Example Transcripts

Try these sample files in the `clarifymeet_meetings/` folder:
- `easy_meeting.txt`: Simple sprint planning
- `medium_meeting.txt`: Product review with decisions
- `difficult_meeting.txt`: Complex technical discussion

## ğŸ“š Learn More

- [Full Documentation](README.md)
- [Streamlit Deployment Guide](STREAMLIT_DEPLOYMENT.md)
- [Detailed Setup](SETUP.md)
- [Ollama Documentation](https://ollama.ai/docs)
- [Streamlit Documentation](https://docs.streamlit.io)

## ğŸ†˜ Need Help?

- Check the troubleshooting section above
- Review the sample transcripts
- Ensure Ollama is running with the right model

## ğŸ‰ You're Ready!

Start analyzing your meeting transcripts with AI! ğŸ¤–

---

**Happy analyzing! ğŸš€**
